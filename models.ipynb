{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from models import TransformerModel, SEQUENCE_LENGTH, N_FEATURES, HIDDEN_SIZE, NUM_LAYERS, NUM_HEADS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivityDataset(Dataset):\n",
    "    def __init__(self, sequences, labels):\n",
    "        self.sequences = sequences\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.sequences[idx], self.labels[idx] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences(data, sequence_length):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    \n",
    "    for i in range(0, len(data) - sequence_length, sequence_length//2):\n",
    "        seq = data[i:i + sequence_length]\n",
    "        if len(seq) == sequence_length:\n",
    "            sequences.append(seq)\n",
    "            labels.append(seq['ActivityLabel'].mode()[0])\n",
    "    \n",
    "    return np.array(sequences), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    BATCH_SIZE = 32\n",
    "    EPOCHS = 100\n",
    "    \n",
    "    df = pd.read_csv('data\\\\combined\\\\merged_users_corrected.csv')\n",
    "    \n",
    "    features = ['AccelX', 'AccelY', 'AccelZ', 'GyroX', 'GyroY', 'GyroZ']\n",
    "    X = df[features]\n",
    "    y = df['ActivityLabel']\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_scaled = pd.DataFrame(X_scaled, columns=features)\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "    \n",
    "    X_scaled['ActivityLabel'] = y_encoded\n",
    "    sequences, labels = prepare_sequences(X_scaled, SEQUENCE_LENGTH)\n",
    "    \n",
    "    sequences = sequences[:, :, :-1].astype(np.float32)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        sequences, labels, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    train_dataset = ActivityDataset(torch.FloatTensor(X_train), torch.LongTensor(y_train))\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    \n",
    "    num_classes = len(label_encoder.classes_)\n",
    "    model = TransformerModel(\n",
    "        input_size=N_FEATURES,\n",
    "        hidden_size=HIDDEN_SIZE,\n",
    "        num_layers=NUM_LAYERS,\n",
    "        num_heads=NUM_HEADS,\n",
    "        num_classes=num_classes\n",
    "    )\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "    best_accuracy = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for sequences, labels in train_loader:\n",
    "            sequences, labels = sequences.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(sequences)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        current_accuracy = 100. * correct / total\n",
    "        print(f'Epoch {epoch+1}/{EPOCHS}, Loss: {train_loss/len(train_loader):.4f}, Accuracy: {current_accuracy:.2f}%')\n",
    "        \n",
    "        if current_accuracy > best_accuracy:\n",
    "            best_accuracy = current_accuracy\n",
    "            best_model_state = model.state_dict()\n",
    "            print(f'New best accuracy: {best_accuracy:.2f}%')\n",
    "    \n",
    "    print(f'Training completed. Best accuracy: {best_accuracy:.2f}%')\n",
    "    torch.save({\n",
    "        'model_state_dict': best_model_state,\n",
    "        'scaler': scaler,\n",
    "        'label_encoder': label_encoder,\n",
    "        'best_accuracy': best_accuracy,\n",
    "    }, 'results\\\\TransformerModelCopilotOptimal_best.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 0.8019, Accuracy: 73.03%\n",
      "Epoch 2/100, Loss: 0.3162, Accuracy: 91.36%\n",
      "Epoch 3/100, Loss: 0.2139, Accuracy: 94.37%\n",
      "Epoch 4/100, Loss: 0.1793, Accuracy: 95.43%\n",
      "Epoch 5/100, Loss: 0.1640, Accuracy: 95.43%\n",
      "Epoch 6/100, Loss: 0.1421, Accuracy: 96.50%\n",
      "Epoch 7/100, Loss: 0.1382, Accuracy: 96.20%\n",
      "Epoch 8/100, Loss: 0.1130, Accuracy: 96.75%\n",
      "Epoch 9/100, Loss: 0.1184, Accuracy: 96.50%\n",
      "Epoch 10/100, Loss: 0.0966, Accuracy: 97.32%\n",
      "Epoch 11/100, Loss: 0.0909, Accuracy: 97.57%\n",
      "Epoch 12/100, Loss: 0.1188, Accuracy: 96.36%\n",
      "Epoch 13/100, Loss: 0.0916, Accuracy: 97.32%\n",
      "Epoch 14/100, Loss: 0.0800, Accuracy: 97.81%\n",
      "Epoch 15/100, Loss: 0.0730, Accuracy: 97.78%\n",
      "Epoch 16/100, Loss: 0.0587, Accuracy: 98.33%\n",
      "Epoch 17/100, Loss: 0.0622, Accuracy: 98.22%\n",
      "Epoch 18/100, Loss: 0.0436, Accuracy: 98.66%\n",
      "Epoch 19/100, Loss: 0.0708, Accuracy: 97.78%\n",
      "Epoch 20/100, Loss: 0.1115, Accuracy: 96.85%\n",
      "Epoch 21/100, Loss: 0.0622, Accuracy: 98.25%\n",
      "Epoch 22/100, Loss: 0.0464, Accuracy: 98.61%\n",
      "Epoch 23/100, Loss: 0.0442, Accuracy: 98.58%\n",
      "Epoch 24/100, Loss: 0.0456, Accuracy: 98.69%\n",
      "Epoch 25/100, Loss: 0.0358, Accuracy: 98.99%\n",
      "Epoch 26/100, Loss: 0.0440, Accuracy: 98.80%\n",
      "Epoch 27/100, Loss: 0.0481, Accuracy: 98.58%\n",
      "Epoch 28/100, Loss: 0.0531, Accuracy: 98.63%\n",
      "Epoch 29/100, Loss: 0.0702, Accuracy: 98.11%\n",
      "Epoch 30/100, Loss: 0.0455, Accuracy: 98.55%\n",
      "Epoch 31/100, Loss: 0.0521, Accuracy: 98.58%\n",
      "Epoch 32/100, Loss: 0.0348, Accuracy: 99.02%\n",
      "Epoch 33/100, Loss: 0.0358, Accuracy: 99.18%\n",
      "Epoch 34/100, Loss: 0.0637, Accuracy: 98.09%\n",
      "Epoch 35/100, Loss: 0.0255, Accuracy: 99.15%\n",
      "Epoch 36/100, Loss: 0.0234, Accuracy: 99.23%\n",
      "Epoch 37/100, Loss: 0.0420, Accuracy: 98.82%\n",
      "Epoch 38/100, Loss: 0.0411, Accuracy: 98.66%\n",
      "Epoch 39/100, Loss: 0.0409, Accuracy: 98.71%\n",
      "Epoch 40/100, Loss: 0.0362, Accuracy: 98.96%\n",
      "Epoch 41/100, Loss: 0.0257, Accuracy: 99.40%\n",
      "Epoch 42/100, Loss: 0.0364, Accuracy: 99.12%\n",
      "Epoch 43/100, Loss: 0.0392, Accuracy: 98.82%\n",
      "Epoch 44/100, Loss: 0.0402, Accuracy: 98.82%\n",
      "Epoch 45/100, Loss: 0.0247, Accuracy: 99.26%\n",
      "Epoch 46/100, Loss: 0.0325, Accuracy: 98.77%\n",
      "Epoch 47/100, Loss: 0.0358, Accuracy: 99.12%\n",
      "Epoch 48/100, Loss: 0.0251, Accuracy: 99.34%\n",
      "Epoch 49/100, Loss: 0.0203, Accuracy: 99.43%\n",
      "Epoch 50/100, Loss: 0.0335, Accuracy: 99.10%\n",
      "Epoch 51/100, Loss: 0.0315, Accuracy: 99.18%\n",
      "Epoch 52/100, Loss: 0.0337, Accuracy: 98.82%\n",
      "Epoch 53/100, Loss: 0.0244, Accuracy: 99.32%\n",
      "Epoch 54/100, Loss: 0.0324, Accuracy: 99.15%\n",
      "Epoch 55/100, Loss: 0.0175, Accuracy: 99.43%\n",
      "Epoch 56/100, Loss: 0.0296, Accuracy: 98.99%\n",
      "Epoch 57/100, Loss: 0.0362, Accuracy: 98.93%\n",
      "Epoch 58/100, Loss: 0.0230, Accuracy: 99.40%\n",
      "Epoch 59/100, Loss: 0.0107, Accuracy: 99.67%\n",
      "Epoch 60/100, Loss: 0.0310, Accuracy: 99.26%\n",
      "Epoch 61/100, Loss: 0.0279, Accuracy: 99.26%\n",
      "Epoch 62/100, Loss: 0.0222, Accuracy: 99.37%\n",
      "Epoch 63/100, Loss: 0.0521, Accuracy: 98.82%\n",
      "Epoch 64/100, Loss: 0.0433, Accuracy: 98.93%\n",
      "Epoch 65/100, Loss: 0.0270, Accuracy: 99.32%\n",
      "Epoch 66/100, Loss: 0.0322, Accuracy: 99.10%\n",
      "Epoch 67/100, Loss: 0.0218, Accuracy: 99.45%\n",
      "Epoch 68/100, Loss: 0.0156, Accuracy: 99.62%\n",
      "Epoch 69/100, Loss: 0.0155, Accuracy: 99.56%\n",
      "Epoch 70/100, Loss: 0.0087, Accuracy: 99.70%\n",
      "Epoch 71/100, Loss: 0.0203, Accuracy: 99.45%\n",
      "Epoch 72/100, Loss: 0.0495, Accuracy: 98.96%\n",
      "Epoch 73/100, Loss: 0.0488, Accuracy: 98.69%\n",
      "Epoch 74/100, Loss: 0.0263, Accuracy: 99.18%\n",
      "Epoch 75/100, Loss: 0.0304, Accuracy: 99.18%\n",
      "Epoch 76/100, Loss: 0.0196, Accuracy: 99.51%\n",
      "Epoch 77/100, Loss: 0.0307, Accuracy: 99.29%\n",
      "Epoch 78/100, Loss: 0.0273, Accuracy: 99.37%\n",
      "Epoch 79/100, Loss: 0.0172, Accuracy: 99.51%\n",
      "Epoch 80/100, Loss: 0.0118, Accuracy: 99.64%\n",
      "Epoch 81/100, Loss: 0.0267, Accuracy: 99.18%\n",
      "Epoch 82/100, Loss: 0.0243, Accuracy: 99.23%\n",
      "Epoch 83/100, Loss: 0.0163, Accuracy: 99.48%\n",
      "Epoch 84/100, Loss: 0.0211, Accuracy: 99.51%\n",
      "Epoch 85/100, Loss: 0.0097, Accuracy: 99.64%\n",
      "Epoch 86/100, Loss: 0.0115, Accuracy: 99.73%\n",
      "Epoch 87/100, Loss: 0.0121, Accuracy: 99.70%\n",
      "Epoch 88/100, Loss: 0.0165, Accuracy: 99.62%\n",
      "Epoch 89/100, Loss: 0.0084, Accuracy: 99.81%\n",
      "Epoch 90/100, Loss: 0.0461, Accuracy: 99.02%\n",
      "Epoch 91/100, Loss: 0.0413, Accuracy: 98.85%\n",
      "Epoch 92/100, Loss: 0.0550, Accuracy: 98.44%\n",
      "Epoch 93/100, Loss: 0.0534, Accuracy: 98.47%\n",
      "Epoch 94/100, Loss: 0.0162, Accuracy: 99.56%\n",
      "Epoch 95/100, Loss: 0.0224, Accuracy: 99.43%\n",
      "Epoch 96/100, Loss: 0.0174, Accuracy: 99.56%\n",
      "Epoch 97/100, Loss: 0.0200, Accuracy: 99.59%\n",
      "Epoch 98/100, Loss: 0.0142, Accuracy: 99.73%\n",
      "Epoch 99/100, Loss: 0.0036, Accuracy: 99.97%\n",
      "Epoch 100/100, Loss: 0.0051, Accuracy: 99.92%\n"
     ]
    }
   ],
   "source": [
    "train_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
